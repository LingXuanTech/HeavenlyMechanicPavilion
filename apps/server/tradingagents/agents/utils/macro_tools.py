"""ç¾è‚¡å®è§‚ç»æµåˆ†æå·¥å…·

æä¾›ç¾è”å‚¨åˆ©ç‡ã€é€šèƒ€ã€å°±ä¸šæ•°æ®ç­‰å®è§‚ç»æµåˆ†æå·¥å…·ã€‚
"""

from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any
from langchain_core.tools import tool
import structlog

try:
    import pandas as pd
except ImportError:
    pd = None

logger = structlog.get_logger(__name__)


def _get_fred_data(series_id: str, start_date: str = None, end_date: str = None) -> List[Dict[str, Any]]:
    """ä» FRED API è·å–æ•°æ®"""
    import os
    try:
        from fredapi import Fred
        api_key = os.getenv("FRED_API_KEY")
        if not api_key:
            logger.warning("FRED_API_KEY not set, using mock data")
            return _get_mock_fred_data(series_id)

        fred = Fred(api_key=api_key)
        if start_date is None:
            start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")

        data = fred.get_series(series_id, observation_start=start_date, observation_end=end_date)
        return [
            {"date": str(date.date()), "value": float(value)}
            for date, value in data.items()
            if not pd.isna(value)
        ]
    except ImportError:
        logger.warning("fredapi not installed, using mock data")
        return _get_mock_fred_data(series_id)
    except Exception as e:
        logger.warning("FRED API failed", series_id=series_id, error=str(e))
        return _get_mock_fred_data(series_id)


def _get_mock_fred_data(series_id: str) -> List[Dict[str, Any]]:
    """è¿”å›æ¨¡æ‹Ÿçš„ FRED æ•°æ®"""
    # æ¨¡æ‹Ÿæ•°æ®ç”¨äºå¼€å‘å’Œæµ‹è¯•
    mock_data = {
        "FEDFUNDS": [  # è”é‚¦åŸºé‡‘åˆ©ç‡
            {"date": "2025-12-01", "value": 4.33},
            {"date": "2025-11-01", "value": 4.58},
            {"date": "2025-10-01", "value": 4.83},
            {"date": "2025-09-01", "value": 5.08},
            {"date": "2025-08-01", "value": 5.33},
        ],
        "CPIAUCSL": [  # CPI æ¶ˆè´¹è€…ä»·æ ¼æŒ‡æ•°
            {"date": "2025-12-01", "value": 315.2},
            {"date": "2025-11-01", "value": 314.8},
            {"date": "2025-10-01", "value": 314.1},
            {"date": "2025-09-01", "value": 313.5},
            {"date": "2025-08-01", "value": 312.8},
        ],
        "UNRATE": [  # å¤±ä¸šç‡
            {"date": "2025-12-01", "value": 4.2},
            {"date": "2025-11-01", "value": 4.1},
            {"date": "2025-10-01", "value": 4.1},
            {"date": "2025-09-01", "value": 4.0},
            {"date": "2025-08-01", "value": 4.2},
        ],
        "PAYEMS": [  # éå†œå°±ä¸šäººæ•°ï¼ˆåƒäººï¼‰
            {"date": "2025-12-01", "value": 159200},
            {"date": "2025-11-01", "value": 159050},
            {"date": "2025-10-01", "value": 158800},
            {"date": "2025-09-01", "value": 158550},
            {"date": "2025-08-01", "value": 158250},
        ],
        "T10Y2Y": [  # 10å¹´-2å¹´å›½å€ºæ”¶ç›Šç‡å·®ï¼ˆæ”¶ç›Šç‡æ›²çº¿ï¼‰
            {"date": "2025-12-01", "value": 0.25},
            {"date": "2025-11-01", "value": 0.15},
            {"date": "2025-10-01", "value": -0.05},
            {"date": "2025-09-01", "value": -0.15},
            {"date": "2025-08-01", "value": -0.25},
        ],
        "GDP": [  # GDPï¼ˆåäº¿ç¾å…ƒï¼‰
            {"date": "2025-10-01", "value": 29500},
            {"date": "2025-07-01", "value": 29200},
            {"date": "2025-04-01", "value": 28900},
            {"date": "2025-01-01", "value": 28600},
        ],
    }
    return mock_data.get(series_id, [])


@tool
def get_fed_rate_data() -> str:
    """è·å–ç¾è”å‚¨è”é‚¦åŸºé‡‘åˆ©ç‡å†å²æ•°æ®

    Returns:
        è”é‚¦åŸºé‡‘åˆ©ç‡å†å²æ•°æ®å’Œè¶‹åŠ¿åˆ†æ
    """
    data = _get_fred_data("FEDFUNDS")

    if not data:
        return "æ— æ³•è·å–è”é‚¦åŸºé‡‘åˆ©ç‡æ•°æ®"

    output_lines = ["## ç¾è”å‚¨è”é‚¦åŸºé‡‘åˆ©ç‡\n"]

    # æœ€æ–°æ•°æ®
    latest = data[0]
    output_lines.append(f"**å½“å‰åˆ©ç‡**: {latest['value']:.2f}%ï¼ˆ{latest['date']}ï¼‰\n")

    # å†å²è¶‹åŠ¿
    output_lines.append("### è¿‘æœŸèµ°åŠ¿")
    for item in data[:6]:
        output_lines.append(f"- {item['date']}: {item['value']:.2f}%")

    # è®¡ç®—å˜åŒ–
    if len(data) >= 2:
        change = data[0]["value"] - data[1]["value"]
        trend = "ä¸Šå‡" if change > 0 else "ä¸‹é™" if change < 0 else "æŒå¹³"
        output_lines.append(f"\n**æœ€è¿‘å˜åŒ–**: {change:+.2f}% ({trend})")

    # å¸‚åœºå½±å“åˆ†æ
    current_rate = data[0]["value"]
    if current_rate > 5:
        impact = "âš ï¸ é«˜åˆ©ç‡ç¯å¢ƒï¼Œå¯¹æˆé•¿è‚¡ä¼°å€¼å‹åŠ›è¾ƒå¤§ï¼Œåˆ©å¥½é“¶è¡Œè‚¡æ¯å·®"
    elif current_rate > 3:
        impact = "ğŸ“Š ä¸­æ€§åˆ©ç‡ç¯å¢ƒï¼Œå…³æ³¨é™æ¯é¢„æœŸå¯¹å¸‚åœºçš„åˆºæ¿€"
    else:
        impact = "ğŸ“ˆ ä½åˆ©ç‡ç¯å¢ƒï¼Œæœ‰åˆ©äºè‚¡ç¥¨ä¼°å€¼æ‰©å¼ "

    output_lines.append(f"\n**å¸‚åœºå½±å“**: {impact}")

    return "\n".join(output_lines)


@tool
def get_inflation_data() -> str:
    """è·å–ç¾å›½é€šèƒ€æ•°æ®ï¼ˆCPIï¼‰

    Returns:
        CPI é€šèƒ€æ•°æ®å’Œåˆ†æ
    """
    data = _get_fred_data("CPIAUCSL")

    if not data or len(data) < 2:
        return "æ— æ³•è·å– CPI æ•°æ®"

    output_lines = ["## ç¾å›½æ¶ˆè´¹è€…ä»·æ ¼æŒ‡æ•°ï¼ˆCPIï¼‰\n"]

    # æœ€æ–°æ•°æ®
    latest = data[0]
    output_lines.append(f"**æœ€æ–° CPI**: {latest['value']:.1f}ï¼ˆ{latest['date']}ï¼‰\n")

    # è®¡ç®—åŒæ¯”å˜åŒ–ï¼ˆç²—ç•¥ä¼°è®¡ï¼‰
    if len(data) >= 12:
        yoy_change = ((data[0]["value"] / data[11]["value"]) - 1) * 100
        output_lines.append(f"**åŒæ¯”å˜åŒ–**: {yoy_change:.1f}%")

    # è®¡ç®—ç¯æ¯”å˜åŒ–
    if len(data) >= 2:
        mom_change = ((data[0]["value"] / data[1]["value"]) - 1) * 100
        output_lines.append(f"**ç¯æ¯”å˜åŒ–**: {mom_change:.2f}%\n")

    # å†å²æ•°æ®
    output_lines.append("### è¿‘æœŸèµ°åŠ¿")
    for item in data[:6]:
        output_lines.append(f"- {item['date']}: {item['value']:.1f}")

    # é€šèƒ€åˆ†æ
    if len(data) >= 12:
        if yoy_change > 4:
            analysis = "âš ï¸ é€šèƒ€è¾ƒé«˜ï¼Œç¾è”å‚¨å¯èƒ½ç»´æŒç´§ç¼©æ”¿ç­–"
        elif yoy_change > 2:
            analysis = "ğŸ“Š é€šèƒ€æ¸©å’Œï¼Œæ¥è¿‘ç¾è”å‚¨ 2% ç›®æ ‡"
        else:
            analysis = "ğŸ“‰ é€šèƒ€è¾ƒä½ï¼Œæœ‰é™æ¯ç©ºé—´"
        output_lines.append(f"\n**é€šèƒ€åˆ†æ**: {analysis}")

    return "\n".join(output_lines)


@tool
def get_employment_data() -> str:
    """è·å–ç¾å›½å°±ä¸šæ•°æ®ï¼ˆå¤±ä¸šç‡å’Œéå†œï¼‰

    Returns:
        å¤±ä¸šç‡å’Œéå†œå°±ä¸šæ•°æ®åŠåˆ†æ
    """
    unemployment = _get_fred_data("UNRATE")
    nonfarm = _get_fred_data("PAYEMS")

    output_lines = ["## ç¾å›½å°±ä¸šæ•°æ®\n"]

    # å¤±ä¸šç‡
    if unemployment:
        latest_ur = unemployment[0]
        output_lines.append(f"### å¤±ä¸šç‡")
        output_lines.append(f"**å½“å‰å¤±ä¸šç‡**: {latest_ur['value']:.1f}%ï¼ˆ{latest_ur['date']}ï¼‰\n")

        for item in unemployment[:4]:
            output_lines.append(f"- {item['date']}: {item['value']:.1f}%")

        # å¤±ä¸šç‡åˆ†æ
        if latest_ur["value"] < 4.0:
            ur_analysis = "åŠ³åŠ¨åŠ›å¸‚åœºç´§å¼ ï¼Œå¯èƒ½æ¨é«˜å·¥èµ„é€šèƒ€"
        elif latest_ur["value"] < 5.0:
            ur_analysis = "åŠ³åŠ¨åŠ›å¸‚åœºå¥åº·ï¼Œå……åˆ†å°±ä¸šçŠ¶æ€"
        else:
            ur_analysis = "å¤±ä¸šç‡åé«˜ï¼Œç»æµæ”¾ç¼“ä¿¡å·"
        output_lines.append(f"\n**å¤±ä¸šç‡åˆ†æ**: {ur_analysis}\n")

    # éå†œå°±ä¸š
    if nonfarm and len(nonfarm) >= 2:
        output_lines.append(f"### éå†œå°±ä¸šäººæ•°")
        latest_nf = nonfarm[0]
        prev_nf = nonfarm[1]
        change = (latest_nf["value"] - prev_nf["value"])

        output_lines.append(f"**æœ€æ–°éå†œ**: {latest_nf['value']/1000:.1f} ç™¾ä¸‡äººï¼ˆ{latest_nf['date']}ï¼‰")
        output_lines.append(f"**æœˆåº¦æ–°å¢**: {change:.0f} åƒäºº\n")

        # éå†œåˆ†æ
        if change > 200:
            nf_analysis = "ğŸ“ˆ å°±ä¸šå¼ºåŠ²å¢é•¿ï¼Œç»æµæ‰©å¼ ä¿¡å·"
        elif change > 100:
            nf_analysis = "ğŸ“Š å°±ä¸šæ¸©å’Œå¢é•¿ï¼Œç»æµç¨³å¥"
        elif change > 0:
            nf_analysis = "ğŸ“‰ å°±ä¸šå¢é•¿æ”¾ç¼“ï¼Œéœ€å…³æ³¨ç»æµåŠ¨èƒ½"
        else:
            nf_analysis = "âš ï¸ å°±ä¸šèç¼©ï¼Œç»æµè¡°é€€é£é™©"
        output_lines.append(f"**éå†œåˆ†æ**: {nf_analysis}")

    return "\n".join(output_lines)


@tool
def get_yield_curve_data() -> str:
    """è·å–ç¾å›½å›½å€ºæ”¶ç›Šç‡æ›²çº¿æ•°æ®

    Returns:
        æ”¶ç›Šç‡æ›²çº¿æ•°æ®ï¼ˆ10å¹´-2å¹´åˆ©å·®ï¼‰å’Œå€’æŒ‚åˆ†æ
    """
    data = _get_fred_data("T10Y2Y")

    if not data:
        return "æ— æ³•è·å–æ”¶ç›Šç‡æ›²çº¿æ•°æ®"

    output_lines = ["## ç¾å›½å›½å€ºæ”¶ç›Šç‡æ›²çº¿ï¼ˆ10Y-2Y åˆ©å·®ï¼‰\n"]

    latest = data[0]
    output_lines.append(f"**å½“å‰åˆ©å·®**: {latest['value']:.2f}%ï¼ˆ{latest['date']}ï¼‰\n")

    # å†å²æ•°æ®
    output_lines.append("### è¿‘æœŸèµ°åŠ¿")
    for item in data[:6]:
        status = "âš ï¸å€’æŒ‚" if item["value"] < 0 else "âœ…æ­£å¸¸"
        output_lines.append(f"- {item['date']}: {item['value']:+.2f}% {status}")

    # å€’æŒ‚åˆ†æ
    if latest["value"] < 0:
        analysis = """
âš ï¸ **æ”¶ç›Šç‡æ›²çº¿å€’æŒ‚**
- å†å²ä¸Šï¼Œæ”¶ç›Šç‡æ›²çº¿å€’æŒ‚é€šå¸¸é¢†å…ˆç»æµè¡°é€€ 6-18 ä¸ªæœˆ
- çŸ­ç«¯åˆ©ç‡é«˜äºé•¿ç«¯ï¼Œåæ˜ å¸‚åœºé¢„æœŸæœªæ¥åˆ©ç‡ä¸‹é™
- å»ºè®®ï¼šé˜²å¾¡æ€§é…ç½®ï¼Œå…³æ³¨æŠ—å‘¨æœŸæ¿å—ï¼ˆå…¬ç”¨äº‹ä¸šã€åŒ»ç–—ä¿å¥ï¼‰
"""
    elif latest["value"] < 0.5:
        analysis = """
ğŸ“Š **æ”¶ç›Šç‡æ›²çº¿å¹³å¦**
- æ›²çº¿æ¥è¿‘å¹³å¦ï¼Œå¸‚åœºå¯¹ç»æµå‰æ™¯å­˜åœ¨åˆ†æ­§
- å¯†åˆ‡å…³æ³¨åç»­èµ°åŠ¿ï¼Œè‹¥è¿›ä¸€æ­¥èµ°å¹³éœ€è°¨æ…
"""
    else:
        analysis = """
ğŸ“ˆ **æ”¶ç›Šç‡æ›²çº¿æ­£å¸¸**
- æ›²çº¿æ­£å¸¸å‘ä¸Šå€¾æ–œï¼Œç»æµæ‰©å¼ é¢„æœŸå¥åº·
- æœ‰åˆ©äºé“¶è¡Œç­‰ä¾èµ–æ¯å·®çš„é‡‘èæœºæ„
"""

    output_lines.append(analysis)

    return "\n".join(output_lines)


@tool
def get_us_macro_summary() -> str:
    """è·å–ç¾å›½å®è§‚ç»æµç»¼åˆæ¦‚è§ˆ

    Returns:
        ç¾å›½å®è§‚ç»æµå„é¡¹æŒ‡æ ‡çš„ç»¼åˆåˆ†æå’ŒæŠ•èµ„å»ºè®®
    """
    # æ”¶é›†å„é¡¹æ•°æ®
    fed_rate = _get_fred_data("FEDFUNDS")
    cpi = _get_fred_data("CPIAUCSL")
    unemployment = _get_fred_data("UNRATE")
    yield_curve = _get_fred_data("T10Y2Y")

    output_lines = ["## ç¾å›½å®è§‚ç»æµç»¼åˆæ¦‚è§ˆ\n"]
    output_lines.append(f"**æ›´æ–°æ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d')}\n")

    # å…³é”®æŒ‡æ ‡æ‘˜è¦
    output_lines.append("### å…³é”®æŒ‡æ ‡")
    output_lines.append("| æŒ‡æ ‡ | æœ€æ–°å€¼ | è¶‹åŠ¿ |")
    output_lines.append("|------|--------|------|")

    if fed_rate:
        rate_trend = "â†“" if len(fed_rate) > 1 and fed_rate[0]["value"] < fed_rate[1]["value"] else "â†’" if len(fed_rate) > 1 and fed_rate[0]["value"] == fed_rate[1]["value"] else "â†‘"
        output_lines.append(f"| è”é‚¦åŸºé‡‘åˆ©ç‡ | {fed_rate[0]['value']:.2f}% | {rate_trend} |")

    if cpi and len(cpi) >= 12:
        yoy_cpi = ((cpi[0]["value"] / cpi[11]["value"]) - 1) * 100
        cpi_trend = "â†“" if yoy_cpi < 3 else "â†’" if yoy_cpi < 4 else "â†‘"
        output_lines.append(f"| CPI åŒæ¯” | {yoy_cpi:.1f}% | {cpi_trend} |")

    if unemployment:
        ur_trend = "â†“" if len(unemployment) > 1 and unemployment[0]["value"] < unemployment[1]["value"] else "â†’" if len(unemployment) > 1 and unemployment[0]["value"] == unemployment[1]["value"] else "â†‘"
        output_lines.append(f"| å¤±ä¸šç‡ | {unemployment[0]['value']:.1f}% | {ur_trend} |")

    if yield_curve:
        yc_trend = "â†‘" if len(yield_curve) > 1 and yield_curve[0]["value"] > yield_curve[1]["value"] else "â†’" if len(yield_curve) > 1 and yield_curve[0]["value"] == yield_curve[1]["value"] else "â†“"
        yc_status = "å€’æŒ‚" if yield_curve[0]["value"] < 0 else "æ­£å¸¸"
        output_lines.append(f"| æ”¶ç›Šç‡æ›²çº¿ | {yield_curve[0]['value']:+.2f}% ({yc_status}) | {yc_trend} |")

    output_lines.append("")

    # ç»¼åˆè¯„ä¼°
    output_lines.append("### ç»¼åˆè¯„ä¼°")

    # è®¡ç®—å®è§‚åˆ†æ•°
    score = 0
    reasons = []

    if fed_rate and fed_rate[0]["value"] < 4.5:
        score += 1
        reasons.append("åˆ©ç‡å¤„äºç›¸å¯¹å®½æ¾åŒºé—´")
    elif fed_rate and fed_rate[0]["value"] > 5.5:
        score -= 1
        reasons.append("é«˜åˆ©ç‡å¯¹ä¼°å€¼æœ‰å‹åˆ¶")

    if cpi and len(cpi) >= 12:
        yoy_cpi = ((cpi[0]["value"] / cpi[11]["value"]) - 1) * 100
        if yoy_cpi < 3:
            score += 1
            reasons.append("é€šèƒ€æ¸©å’Œï¼Œæ”¿ç­–ç©ºé—´å¤§")
        elif yoy_cpi > 4:
            score -= 1
            reasons.append("é€šèƒ€åé«˜ï¼Œæ”¿ç­–å¯èƒ½åç´§")

    if unemployment and unemployment[0]["value"] < 4.5:
        score += 1
        reasons.append("å°±ä¸šå¸‚åœºå¥åº·")
    elif unemployment and unemployment[0]["value"] > 5.5:
        score -= 1
        reasons.append("å¤±ä¸šç‡åé«˜ï¼Œç»æµæ”¾ç¼“")

    if yield_curve and yield_curve[0]["value"] < 0:
        score -= 2
        reasons.append("æ”¶ç›Šç‡æ›²çº¿å€’æŒ‚ï¼Œè¡°é€€é¢„è­¦")
    elif yield_curve and yield_curve[0]["value"] > 0.5:
        score += 1
        reasons.append("æ”¶ç›Šç‡æ›²çº¿æ­£å¸¸")

    # è¾“å‡ºè¯„ä¼°ç»“æœ
    for reason in reasons:
        output_lines.append(f"- {reason}")

    output_lines.append("")

    # æŠ•èµ„å»ºè®®
    output_lines.append("### æŠ•èµ„å»ºè®®")
    if score >= 2:
        output_lines.append("**å®è§‚ç¯å¢ƒè¯„ä¼°**: ğŸ“ˆ **æœ‰åˆ©**")
        output_lines.append("- å»ºè®®ï¼šå¯é€‚åº¦å¢åŠ é£é™©æ•å£")
        output_lines.append("- åå¥½ï¼šæˆé•¿è‚¡ã€å‘¨æœŸè‚¡")
        output_lines.append("- è§„é¿ï¼šè¿‡äºä¿å®ˆçš„é…ç½®")
    elif score >= 0:
        output_lines.append("**å®è§‚ç¯å¢ƒè¯„ä¼°**: ğŸ“Š **ä¸­æ€§**")
        output_lines.append("- å»ºè®®ï¼šå‡è¡¡é…ç½®")
        output_lines.append("- åå¥½ï¼šä¼˜è´¨è“ç­¹ã€è‚¡æ¯è‚¡")
        output_lines.append("- è§„é¿ï¼šé«˜æ æ†ã€é«˜ä¼°å€¼")
    else:
        output_lines.append("**å®è§‚ç¯å¢ƒè¯„ä¼°**: âš ï¸ **è°¨æ…**")
        output_lines.append("- å»ºè®®ï¼šé˜²å¾¡æ€§é…ç½®ï¼Œæ§åˆ¶ä»“ä½")
        output_lines.append("- åå¥½ï¼šå…¬ç”¨äº‹ä¸šã€åŒ»ç–—ä¿å¥ã€å¿…éœ€æ¶ˆè´¹")
        output_lines.append("- è§„é¿ï¼šå‘¨æœŸè‚¡ã€é«˜è´å¡”è‚¡")

    return "\n".join(output_lines)


@tool
def calculate_rate_sensitivity(sector: str) -> str:
    """åˆ†æç‰¹å®šè¡Œä¸šå¯¹åˆ©ç‡å˜åŒ–çš„æ•æ„Ÿåº¦

    Args:
        sector: è¡Œä¸šåç§°ï¼ˆå¦‚ï¼štechnology, financials, real_estate, utilitiesï¼‰

    Returns:
        è¯¥è¡Œä¸šå¯¹åˆ©ç‡å˜åŒ–çš„æ•æ„Ÿåº¦åˆ†æ
    """
    # è¡Œä¸šåˆ©ç‡æ•æ„Ÿåº¦æ•°æ®åº“
    sector_sensitivity = {
        "technology": {
            "sensitivity": "é«˜",
            "direction": "è´Ÿç›¸å…³",
            "reason": "é«˜æˆé•¿è‚¡ä¾èµ–è¿œæœŸç°é‡‘æµï¼Œè´´ç°ç‡ä¸Šå‡å¯¹ä¼°å€¼å½±å“å¤§",
            "rate_up_impact": "åˆ©ç©º - ä¼°å€¼æ”¶ç¼©",
            "rate_down_impact": "åˆ©å¥½ - ä¼°å€¼æ‰©å¼ ",
            "subsectors": ["è½¯ä»¶", "åŠå¯¼ä½“", "äº‘è®¡ç®—"],
        },
        "financials": {
            "sensitivity": "é«˜",
            "direction": "æ­£ç›¸å…³",
            "reason": "é“¶è¡Œä¾èµ–å‡€æ¯å·®ï¼Œä¿é™©å…¬å¸æŠ•èµ„æ”¶ç›Šå—ç›Šäºé«˜åˆ©ç‡",
            "rate_up_impact": "åˆ©å¥½ - å‡€æ¯å·®æ‰©å¤§",
            "rate_down_impact": "åˆ©ç©º - å‡€æ¯å·®æ”¶çª„",
            "subsectors": ["é“¶è¡Œ", "ä¿é™©", "åˆ¸å•†"],
        },
        "real_estate": {
            "sensitivity": "æé«˜",
            "direction": "è´Ÿç›¸å…³",
            "reason": "æˆ¿åœ°äº§é«˜åº¦ä¾èµ–èèµ„æˆæœ¬ï¼Œåˆ©ç‡ä¸Šå‡å¢åŠ è´­æˆ¿å’Œå¼€å‘æˆæœ¬",
            "rate_up_impact": "é‡å¤§åˆ©ç©º - èèµ„æˆæœ¬ä¸Šå‡",
            "rate_down_impact": "é‡å¤§åˆ©å¥½ - èèµ„æˆæœ¬ä¸‹é™",
            "subsectors": ["REITs", "æˆ¿åœ°äº§å¼€å‘", "ç‰©ä¸šç®¡ç†"],
        },
        "utilities": {
            "sensitivity": "ä¸­",
            "direction": "è´Ÿç›¸å…³",
            "reason": "å…¬ç”¨äº‹ä¸šè¢«è§†ä¸ºå€ºåˆ¸æ›¿ä»£å“ï¼Œåˆ©ç‡ä¸Šå‡é™ä½å…¶å¸å¼•åŠ›",
            "rate_up_impact": "åˆ©ç©º - ç›¸å¯¹å¸å¼•åŠ›ä¸‹é™",
            "rate_down_impact": "åˆ©å¥½ - è‚¡æ¯å¸å¼•åŠ›ä¸Šå‡",
            "subsectors": ["ç”µåŠ›", "å¤©ç„¶æ°”", "æ°´åŠ¡"],
        },
        "consumer_discretionary": {
            "sensitivity": "ä¸­é«˜",
            "direction": "è´Ÿç›¸å…³",
            "reason": "æ¶ˆè´¹è´·æ¬¾æˆæœ¬ä¸Šå‡æŠ‘åˆ¶å¤§é¢æ¶ˆè´¹",
            "rate_up_impact": "åˆ©ç©º - æ¶ˆè´¹ä¿¡è´·æˆæœ¬ä¸Šå‡",
            "rate_down_impact": "åˆ©å¥½ - åˆºæ¿€æ¶ˆè´¹",
            "subsectors": ["æ±½è½¦", "é›¶å”®", "é…’åº—æ—…æ¸¸"],
        },
        "healthcare": {
            "sensitivity": "ä½",
            "direction": "ä¸­æ€§",
            "reason": "åŒ»ç–—éœ€æ±‚åˆšæ€§ï¼Œå—åˆ©ç‡å½±å“è¾ƒå°",
            "rate_up_impact": "å½±å“æœ‰é™",
            "rate_down_impact": "å½±å“æœ‰é™",
            "subsectors": ["åˆ¶è¯", "åŒ»ç–—å™¨æ¢°", "åŒ»ç–—æœåŠ¡"],
        },
        "energy": {
            "sensitivity": "ä½",
            "direction": "ä¸­æ€§",
            "reason": "èƒ½æºä»·æ ¼ä¸»è¦å—ä¾›éœ€å½±å“ï¼Œåˆ©ç‡æ•æ„Ÿåº¦ä½",
            "rate_up_impact": "é—´æ¥å½±å“ - ç¾å…ƒèµ°å¼ºå¯èƒ½å‹åˆ¶æ²¹ä»·",
            "rate_down_impact": "é—´æ¥å½±å“ - ç¾å…ƒèµ°å¼±å¯èƒ½æ”¯æ’‘æ²¹ä»·",
            "subsectors": ["çŸ³æ²¹å¤©ç„¶æ°”", "æ²¹æœ", "æ–°èƒ½æº"],
        },
    }

    # æ ‡å‡†åŒ–è¡Œä¸šåç§°
    sector_lower = sector.lower().replace(" ", "_")
    sector_mapping = {
        "tech": "technology",
        "ç§‘æŠ€": "technology",
        "é‡‘è": "financials",
        "banks": "financials",
        "é“¶è¡Œ": "financials",
        "åœ°äº§": "real_estate",
        "æˆ¿åœ°äº§": "real_estate",
        "reits": "real_estate",
        "å…¬ç”¨äº‹ä¸š": "utilities",
        "ç”µåŠ›": "utilities",
        "å¯é€‰æ¶ˆè´¹": "consumer_discretionary",
        "æ¶ˆè´¹": "consumer_discretionary",
        "åŒ»ç–—": "healthcare",
        "åŒ»è¯": "healthcare",
        "èƒ½æº": "energy",
        "çŸ³æ²¹": "energy",
    }

    normalized_sector = sector_mapping.get(sector_lower, sector_lower)

    if normalized_sector not in sector_sensitivity:
        return f"æœªæ‰¾åˆ° '{sector}' è¡Œä¸šçš„åˆ©ç‡æ•æ„Ÿåº¦æ•°æ®ã€‚æ”¯æŒçš„è¡Œä¸šï¼štechnology, financials, real_estate, utilities, consumer_discretionary, healthcare, energy"

    info = sector_sensitivity[normalized_sector]

    output_lines = [f"## {sector} è¡Œä¸šåˆ©ç‡æ•æ„Ÿåº¦åˆ†æ\n"]
    output_lines.append(f"**æ•æ„Ÿåº¦ç­‰çº§**: {info['sensitivity']}")
    output_lines.append(f"**ä¸åˆ©ç‡å…³ç³»**: {info['direction']}")
    output_lines.append(f"\n**åŸå› **: {info['reason']}\n")
    output_lines.append(f"### åˆ©ç‡å˜åŒ–å½±å“")
    output_lines.append(f"- **åˆ©ç‡ä¸Šå‡**: {info['rate_up_impact']}")
    output_lines.append(f"- **åˆ©ç‡ä¸‹é™**: {info['rate_down_impact']}")
    output_lines.append(f"\n**ç›¸å…³å­è¡Œä¸š**: {', '.join(info['subsectors'])}")

    return "\n".join(output_lines)


# ============ å¤®è¡Œ NLP åˆ†æå·¥å…· ============

@tool
def analyze_central_bank_text(text: str) -> str:
    """åˆ†æå¤®è¡ŒæŠ¥å‘Šæˆ–è®²è¯çš„æ”¿ç­–å€¾å‘

    è¯†åˆ«æ–‡æœ¬çš„é¹°æ´¾/é¸½æ´¾å€¾å‘ï¼Œæå–æ”¿ç­–ä¿¡å·ã€‚

    Args:
        text: å¤®è¡ŒæŠ¥å‘Šæˆ–è®²è¯æ–‡æœ¬

    Returns:
        æ”¿ç­–æƒ…ç»ªåˆ†ææŠ¥å‘Š
    """
    try:
        from services.central_bank_nlp_service import central_bank_nlp_service

        # åˆ†ææƒ…ç»ª
        sentiment = central_bank_nlp_service.analyze_sentiment(text)

        # æå–æ”¿ç­–ä¿¡å·
        signals = central_bank_nlp_service.extract_policy_signals(text)

        # é¢„æµ‹æ”¿ç­–å˜åŒ–
        changes = central_bank_nlp_service.predict_policy_change(text)

        # æ„å»ºæŠ¥å‘Š
        output_lines = ["## å¤®è¡Œæ–‡æœ¬åˆ†ææŠ¥å‘Š\n"]

        # æƒ…ç»ªåˆ†æ
        stance_emoji = {"hawkish": "ğŸ¦…", "dovish": "ğŸ•Šï¸", "neutral": "â¡ï¸"}
        emoji = stance_emoji.get(sentiment.stance, "â“")

        output_lines.append(f"### {emoji} æ”¿ç­–ç«‹åœº: {sentiment.stance.upper()}")
        output_lines.append(f"- **ç½®ä¿¡åº¦**: {sentiment.confidence:.0%}")
        output_lines.append(f"- **æƒ…ç»ªè¯„åˆ†**: {sentiment.score:.3f} (-1=æåº¦é¸½æ´¾, 1=æåº¦é¹°æ´¾)\n")

        # é¹°æ´¾/é¸½æ´¾ä¿¡å·
        if sentiment.hawkish_signals:
            output_lines.append("### é¹°æ´¾ä¿¡å·")
            for s in sentiment.hawkish_signals[:5]:
                output_lines.append(f"- {s}")
            output_lines.append("")

        if sentiment.dovish_signals:
            output_lines.append("### é¸½æ´¾ä¿¡å·")
            for s in sentiment.dovish_signals[:5]:
                output_lines.append(f"- {s}")
            output_lines.append("")

        # æ”¿ç­–ä¿¡å·
        if signals:
            output_lines.append("### æ”¿ç­–ä¿¡å·")
            for signal in signals:
                output_lines.append(f"- ğŸ“Œ {signal}")
            output_lines.append("")

        # æ”¿ç­–å˜åŒ–é¢„æµ‹
        if changes:
            output_lines.append("### æ”¿ç­–å˜åŒ–é¢„æµ‹")
            for change in changes:
                output_lines.append(
                    f"- **{change.signal_type}**: "
                    f"æ¦‚ç‡ {change.probability:.0%}ï¼Œé¢„æœŸ {change.timeline}"
                )
                output_lines.append(f"  å¸‚åœºå½±å“: {change.market_impact}")
            output_lines.append("")

        return "\n".join(output_lines)

    except Exception as e:
        logger.warning("Failed to analyze central bank text", error=str(e))
        return f"å¤®è¡Œæ–‡æœ¬åˆ†æå¤±è´¥: {str(e)}"


@tool
def compare_central_bank_statements(current_text: str, previous_text: str) -> str:
    """å¯¹æ¯”ä¸¤æ¬¡å¤®è¡Œå£°æ˜çš„å˜åŒ–

    åˆ†ææ”¿ç­–ç«‹åœºçš„å˜åŒ–è¶‹åŠ¿ã€‚

    Args:
        current_text: å½“å‰å£°æ˜æ–‡æœ¬
        previous_text: ä¸Šæ¬¡å£°æ˜æ–‡æœ¬

    Returns:
        å˜åŒ–åˆ†ææŠ¥å‘Š
    """
    try:
        from services.central_bank_nlp_service import central_bank_nlp_service

        comparison = central_bank_nlp_service.compare_statements(current_text, previous_text)

        output_lines = ["## å¤®è¡Œå£°æ˜å˜åŒ–åˆ†æ\n"]

        # ç«‹åœºå˜åŒ–
        change_emoji = {
            "æ›´åŠ é¹°æ´¾": "ğŸ”¼ğŸ¦…",
            "æ›´åŠ é¸½æ´¾": "ğŸ”½ğŸ•Šï¸",
            "åŸºæœ¬ä¸å˜": "â¡ï¸",
        }
        emoji = change_emoji.get(comparison["stance_change"], "â“")

        output_lines.append(f"### {emoji} ç«‹åœºå˜åŒ–: {comparison['stance_change']}")
        output_lines.append(f"- **å½“å‰ç«‹åœº**: {comparison['current_stance']} (è¯„åˆ†: {comparison['current_score']:.3f})")
        output_lines.append(f"- **ä¸Šæ¬¡ç«‹åœº**: {comparison['previous_stance']} (è¯„åˆ†: {comparison['previous_score']:.3f})")
        output_lines.append(f"- **è¯„åˆ†å˜åŒ–**: {comparison['score_change']:+.3f}\n")

        # å…³é”®è¯å˜åŒ–
        if comparison["added_keywords"]:
            output_lines.append("### æ–°å¢å…³é”®è¯")
            output_lines.append(f"- {', '.join(comparison['added_keywords'][:10])}")
            output_lines.append("")

        if comparison["removed_keywords"]:
            output_lines.append("### åˆ é™¤å…³é”®è¯")
            output_lines.append(f"- {', '.join(comparison['removed_keywords'][:10])}")
            output_lines.append("")

        # è§£è¯»
        output_lines.append("### å˜åŒ–è§£è¯»")
        output_lines.append(comparison["interpretation"])

        return "\n".join(output_lines)

    except Exception as e:
        logger.warning("Failed to compare statements", error=str(e))
        return f"å£°æ˜å¯¹æ¯”åˆ†æå¤±è´¥: {str(e)}"


# ============ è·¨èµ„äº§è”åŠ¨åˆ†æå·¥å…· ============

@tool
def get_cross_asset_analysis() -> str:
    """è·å–è·¨èµ„äº§è”åŠ¨åˆ†æ

    åˆ†æè‚¡ã€å€ºã€æ±‡ã€å•†å“ä¹‹é—´çš„è”åŠ¨å…³ç³»ï¼ŒåŒ…æ‹¬ï¼š
    - æ ¸å¿ƒèµ„äº§ä»·æ ¼å¿«ç…§
    - Risk-On/Risk-Off æ¨¡å¼è¯†åˆ«
    - è·¨èµ„äº§èƒŒç¦»ä¿¡å·
    - å¸‚åœºå™äº‹å’Œå¯æ“ä½œå»ºè®®

    Returns:
        è·¨èµ„äº§è”åŠ¨åˆ†ææŠ¥å‘Š
    """
    try:
        import asyncio
        from services.cross_asset_service import cross_asset_service

        # è¿è¡Œå¼‚æ­¥åˆ†æ
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            result = loop.run_until_complete(cross_asset_service.get_full_analysis())
        finally:
            loop.close()

        output_lines = ["## è·¨èµ„äº§è”åŠ¨åˆ†æ\n"]
        output_lines.append(f"**åˆ†ææ—¶é—´**: {result.analyzed_at.strftime('%Y-%m-%d %H:%M')}\n")

        # é£é™©åå¥½
        risk = result.risk_appetite
        regime_emoji = {"risk_on": "ğŸ“ˆ", "risk_off": "ğŸ“‰", "neutral": "â¡ï¸"}
        output_lines.append(f"### {regime_emoji.get(risk.regime, 'â“')} å¸‚åœºé£é™©åå¥½: {risk.regime.upper()}")
        output_lines.append(f"- **é£é™©è¯„åˆ†**: {risk.score:.0f} (-100 æé¿é™© ~ 100 æå†’é™©)")
        output_lines.append(f"- **ç½®ä¿¡åº¦**: {risk.confidence:.0%}")
        output_lines.append(f"- **è§£è¯»**: {risk.interpretation}\n")

        # æ”¯æŒ/ç›¸åä¿¡å·
        if risk.supporting_signals:
            output_lines.append("**æ”¯æŒä¿¡å·**:")
            for s in risk.supporting_signals[:5]:
                output_lines.append(f"- {s}")
            output_lines.append("")

        if risk.contrary_signals:
            output_lines.append("**ç›¸åä¿¡å·**:")
            for s in risk.contrary_signals[:3]:
                output_lines.append(f"- {s}")
            output_lines.append("")

        # èµ„äº§ä»·æ ¼æ‘˜è¦
        output_lines.append("### æ ¸å¿ƒèµ„äº§ä»·æ ¼")
        output_lines.append("| èµ„äº§ | ä»·æ ¼ | æ—¥æ¶¨è·Œ | 5æ—¥æ¶¨è·Œ |")
        output_lines.append("|------|------|--------|---------|")
        for asset in result.asset_prices[:10]:
            change_1d = f"{asset.change_1d:+.1f}%" if asset.change_1d else "-"
            change_5d = f"{asset.change_5d:+.1f}%" if asset.change_5d else "-"
            output_lines.append(f"| {asset.name} | {asset.price:.2f} | {change_1d} | {change_5d} |")
        output_lines.append("")

        # èƒŒç¦»ä¿¡å·
        if result.divergences:
            output_lines.append("### âš ï¸ è·¨èµ„äº§èƒŒç¦»ä¿¡å·")
            for div in result.divergences:
                severity_emoji = {"severe": "ğŸ”´", "moderate": "ğŸŸ¡", "mild": "ğŸŸ¢"}
                output_lines.append(f"**{severity_emoji.get(div.severity, 'âšª')} {div.signal_type}**: {div.description}")
                output_lines.append(f"- å†å²è§£å†³æ–¹å¼: {div.historical_resolution}")
                output_lines.append(f"- äº¤æ˜“å«ä¹‰: {div.trading_implication}")
                output_lines.append("")

        # å¸‚åœºå™äº‹
        output_lines.append("### å¸‚åœºå™äº‹")
        output_lines.append(result.market_narrative + "\n")

        # å¯æ“ä½œå»ºè®®
        output_lines.append("### å¯æ“ä½œå»ºè®®")
        for insight in result.actionable_insights:
            output_lines.append(f"- {insight}")

        return "\n".join(output_lines)

    except Exception as e:
        logger.warning("Failed to get cross asset analysis", error=str(e))
        return f"è·¨èµ„äº§åˆ†æå¤±è´¥: {str(e)}"


@tool
def get_risk_appetite_signal() -> str:
    """è·å–å¸‚åœºé£é™©åå¥½ä¿¡å·

    åŸºäºå¤šèµ„äº§è¡¨ç°åˆ¤æ–­å½“å‰ Risk-On/Risk-Off çŠ¶æ€ã€‚

    Returns:
        é£é™©åå¥½ä¿¡å·åˆ†æ
    """
    try:
        import asyncio
        from services.cross_asset_service import cross_asset_service

        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            result = loop.run_until_complete(cross_asset_service.calculate_risk_appetite())
        finally:
            loop.close()

        output_lines = ["## å¸‚åœºé£é™©åå¥½ä¿¡å·\n"]
        output_lines.append(f"**æ—¥æœŸ**: {result.date}\n")

        regime_map = {
            "risk_on": ("ğŸ“ˆ Risk-On", "é£é™©åå¥½ä¸Šå‡ï¼Œèµ„é‡‘æµå‘é£é™©èµ„äº§"),
            "risk_off": ("ğŸ“‰ Risk-Off", "é¿é™©æƒ…ç»ªä¸»å¯¼ï¼Œèµ„é‡‘æµå‘é¿é™©èµ„äº§"),
            "neutral": ("â¡ï¸ ä¸­æ€§", "å¤šç©ºåŠ›é‡å¹³è¡¡ï¼Œæ–¹å‘ä¸æ˜"),
        }
        regime_label, regime_desc = regime_map.get(result.regime, ("â“", "æœªçŸ¥"))

        output_lines.append(f"### {regime_label}")
        output_lines.append(f"**è¯„åˆ†**: {result.score:.0f} / 100")
        output_lines.append(f"**ç½®ä¿¡åº¦**: {result.confidence:.0%}")
        output_lines.append(f"**ç‰¹å¾**: {regime_desc}\n")

        output_lines.append("### è§£è¯»")
        output_lines.append(result.interpretation + "\n")

        if result.supporting_signals:
            output_lines.append("### æ”¯æŒä¿¡å·")
            for s in result.supporting_signals:
                output_lines.append(f"- âœ… {s}")
            output_lines.append("")

        if result.contrary_signals:
            output_lines.append("### ç›¸åä¿¡å·")
            for s in result.contrary_signals:
                output_lines.append(f"- âš ï¸ {s}")

        return "\n".join(output_lines)

    except Exception as e:
        logger.warning("Failed to get risk appetite signal", error=str(e))
        return f"é£é™©åå¥½ä¿¡å·è·å–å¤±è´¥: {str(e)}"


# å¯¼å‡ºæ‰€æœ‰å·¥å…·
MACRO_TOOLS = [
    get_fed_rate_data,
    get_inflation_data,
    get_employment_data,
    get_yield_curve_data,
    get_us_macro_summary,
    calculate_rate_sensitivity,
    analyze_central_bank_text,
    compare_central_bank_statements,
    get_cross_asset_analysis,
    get_risk_appetite_signal,
]
